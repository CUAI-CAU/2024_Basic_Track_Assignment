{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d57320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff2c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.7\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "\n",
    "print(hyperopt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0e205",
   "metadata": {},
   "source": [
    "### HyperOpt\n",
    "- GridSearch의 방식으로는 파라미터가 많은 경우 시간이 오래걸림\n",
    "- XGBoost나 LightGBM은 파라미터가 많으므로 무리가 있을 수 있음\n",
    "- 이때 베이지안 최적화 기법을 사용할 수 있음\n",
    "- 베이지안 확률에 기반을 두고있는 최적화 기법임\n",
    "- 이를 구성하는 두가지 중요 요소는 대체 모델과 획득 함수임.\n",
    "- 대체 모델은 획득 함수로부터 최적 함수를 예측할 수 있는 입력값을 추천받은 뒤 이를 기반으로 최적 함수 모델을 개선해나가며, 획득함수는 개선된 대체모델을 기반으로 최적 입력값을 계산함.\n",
    "- 베이지안 최적화를 하이퍼파라미터 튜닝에 이용할 때, 입력값은 하이퍼 파라미터가 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e4e3a",
   "metadata": {},
   "source": [
    "#### 베이지안 최적화의 과정\n",
    "1) 랜덤하게 하이퍼 파라미터를 샘플링하고 성능결과를 관측함\n",
    "2) 관측된 값을 기반으로 대체모델이 최적함수를 추정함.\n",
    "3) 추정된 최적함수를 기반으로 획득함수는 다음으로 관측할 하이퍼파라미터 값을 계산함. 획득함수는 이전의 최적 관찰값보다 더 큰 최대값을 가질 가능성이 높은 지점을 찾아서 다음에 관측할 하이퍼파라미터를 대체모델에 전달함.\n",
    "4) 획득함수로부터 전달된 하이퍼파라미터를 수행하여 관측된 값을 기반으로 대체모델은 갱신되어 다시 최적함수를 예측 추정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21d050",
   "metadata": {},
   "source": [
    "### HyperOpt의 활용 로직\n",
    "1) 입력 변수명과 입력값의 검색공간(Search Space)를 설정함\n",
    "2) 목적 함수(Objective Function)을 설정함\n",
    "3) 목적 함수의 반환 최소값을 가지는 최적 입력값을 유추함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59720ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x와 -15 ~ 15까지 1간격으로 입력 변수 y 설정.\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1), 'y': hp.quniform('y', -15, 15, 1) }\n",
    "\n",
    "# hp.quniform(label, low, high, q): label로 지정된 입력값 변수 검색공간을 최솟값 low에서 최댓값 high까지 q의 간격을 가지고 설정\n",
    "# hp.uniform(label, low, high): 최솟값 low에서 최댓값 high까지 정규분포형태의 검색공간 설정\n",
    "# hp.randint(label, upper): 0부터 최댓값 upper까지 random한 정숫값으로 검색공간 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ecdd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0022844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1132.49trial/s, best loss: -224.0]\n",
      "best: {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5\n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29e3a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1804.31trial/s, best loss: -296.0]\n",
      "best: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20\n",
    "               , trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69910b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin( )에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값} 와 같은 딕셔너리임. \n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f52a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3596f8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성. \n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성.\n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'], 'y': trial_val.vals['y'], 'losses': losses})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955aa8d",
   "metadata": {},
   "source": [
    "### HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드는 이전에 수록된 코드라 책에는 싣지 않았습니다. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']= dataset.target\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e2762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label, test_size=0.2, random_state=156 )\n",
    "\n",
    "# 앞에서 추출한 학습 데이터를 다시 학습과 검증 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca5d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색.\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc2d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "     ---------------------------------------- 99.8/99.8 MB 9.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\caukd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.9.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\caukd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.23.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\caukd\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# 정확도는 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    \n",
    "    # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc927169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.09trial/s, best loss: -0.9670616939700244]\n",
      "best: {'colsample_bytree': 0.684441779397407, 'learning_rate': 0.1475201153968472, 'max_depth': 9.0, 'min_child_weight': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77da755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_bytree:0.68444, learning_rate:0.14752, max_depth:9, min_child_weight:2\n"
     ]
    }
   ],
   "source": [
    "print('colsample_bytree:{0}, learning_rate:{1}, max_depth:{2}, min_child_weight:{3}'.format(\n",
    "    round(best['colsample_bytree'], 5), round(best['learning_rate'], 5),\n",
    "    int(best['max_depth']), int(best['min_child_weight'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c05a7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d44ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.55271\tvalidation_1-logloss:0.58669\n",
      "[1]\tvalidation_0-logloss:0.46532\tvalidation_1-logloss:0.52479\n",
      "[2]\tvalidation_0-logloss:0.39616\tvalidation_1-logloss:0.46923\n",
      "[3]\tvalidation_0-logloss:0.34165\tvalidation_1-logloss:0.42858\n",
      "[4]\tvalidation_0-logloss:0.29745\tvalidation_1-logloss:0.39483\n",
      "[5]\tvalidation_0-logloss:0.25934\tvalidation_1-logloss:0.36657\n",
      "[6]\tvalidation_0-logloss:0.22862\tvalidation_1-logloss:0.35072\n",
      "[7]\tvalidation_0-logloss:0.20367\tvalidation_1-logloss:0.33159\n",
      "[8]\tvalidation_0-logloss:0.18239\tvalidation_1-logloss:0.32347\n",
      "[9]\tvalidation_0-logloss:0.16291\tvalidation_1-logloss:0.30890\n",
      "[10]\tvalidation_0-logloss:0.14780\tvalidation_1-logloss:0.30568\n",
      "[11]\tvalidation_0-logloss:0.13390\tvalidation_1-logloss:0.29906\n",
      "[12]\tvalidation_0-logloss:0.12276\tvalidation_1-logloss:0.28876\n",
      "[13]\tvalidation_0-logloss:0.11289\tvalidation_1-logloss:0.28343\n",
      "[14]\tvalidation_0-logloss:0.10346\tvalidation_1-logloss:0.27987\n",
      "[15]\tvalidation_0-logloss:0.09554\tvalidation_1-logloss:0.27622\n",
      "[16]\tvalidation_0-logloss:0.08826\tvalidation_1-logloss:0.27372\n",
      "[17]\tvalidation_0-logloss:0.08247\tvalidation_1-logloss:0.27294\n",
      "[18]\tvalidation_0-logloss:0.07739\tvalidation_1-logloss:0.26674\n",
      "[19]\tvalidation_0-logloss:0.07293\tvalidation_1-logloss:0.26352\n",
      "[20]\tvalidation_0-logloss:0.06751\tvalidation_1-logloss:0.26310\n",
      "[21]\tvalidation_0-logloss:0.06306\tvalidation_1-logloss:0.25711\n",
      "[22]\tvalidation_0-logloss:0.05846\tvalidation_1-logloss:0.25678\n",
      "[23]\tvalidation_0-logloss:0.05452\tvalidation_1-logloss:0.25732\n",
      "[24]\tvalidation_0-logloss:0.05132\tvalidation_1-logloss:0.25525\n",
      "[25]\tvalidation_0-logloss:0.04834\tvalidation_1-logloss:0.25395\n",
      "[26]\tvalidation_0-logloss:0.04550\tvalidation_1-logloss:0.25433\n",
      "[27]\tvalidation_0-logloss:0.04313\tvalidation_1-logloss:0.25181\n",
      "[28]\tvalidation_0-logloss:0.04134\tvalidation_1-logloss:0.25446\n",
      "[29]\tvalidation_0-logloss:0.03934\tvalidation_1-logloss:0.25551\n",
      "[30]\tvalidation_0-logloss:0.03736\tvalidation_1-logloss:0.25798\n",
      "[31]\tvalidation_0-logloss:0.03579\tvalidation_1-logloss:0.25839\n",
      "[32]\tvalidation_0-logloss:0.03441\tvalidation_1-logloss:0.25869\n",
      "[33]\tvalidation_0-logloss:0.03305\tvalidation_1-logloss:0.26211\n",
      "[34]\tvalidation_0-logloss:0.03201\tvalidation_1-logloss:0.26126\n",
      "[35]\tvalidation_0-logloss:0.03106\tvalidation_1-logloss:0.26290\n",
      "[36]\tvalidation_0-logloss:0.03012\tvalidation_1-logloss:0.26363\n",
      "[37]\tvalidation_0-logloss:0.02941\tvalidation_1-logloss:0.26196\n",
      "[38]\tvalidation_0-logloss:0.02882\tvalidation_1-logloss:0.26225\n",
      "[39]\tvalidation_0-logloss:0.02817\tvalidation_1-logloss:0.26081\n",
      "[40]\tvalidation_0-logloss:0.02744\tvalidation_1-logloss:0.26035\n",
      "[41]\tvalidation_0-logloss:0.02672\tvalidation_1-logloss:0.26134\n",
      "[42]\tvalidation_0-logloss:0.02617\tvalidation_1-logloss:0.25945\n",
      "[43]\tvalidation_0-logloss:0.02571\tvalidation_1-logloss:0.25466\n",
      "[44]\tvalidation_0-logloss:0.02529\tvalidation_1-logloss:0.25783\n",
      "[45]\tvalidation_0-logloss:0.02503\tvalidation_1-logloss:0.25761\n",
      "[46]\tvalidation_0-logloss:0.02461\tvalidation_1-logloss:0.25833\n",
      "[47]\tvalidation_0-logloss:0.02410\tvalidation_1-logloss:0.25943\n",
      "[48]\tvalidation_0-logloss:0.02376\tvalidation_1-logloss:0.26181\n",
      "[49]\tvalidation_0-logloss:0.02356\tvalidation_1-logloss:0.26174\n",
      "[50]\tvalidation_0-logloss:0.02298\tvalidation_1-logloss:0.25764\n",
      "[51]\tvalidation_0-logloss:0.02279\tvalidation_1-logloss:0.25746\n",
      "[52]\tvalidation_0-logloss:0.02246\tvalidation_1-logloss:0.25602\n",
      "[53]\tvalidation_0-logloss:0.02230\tvalidation_1-logloss:0.25588\n",
      "[54]\tvalidation_0-logloss:0.02212\tvalidation_1-logloss:0.25788\n",
      "[55]\tvalidation_0-logloss:0.02170\tvalidation_1-logloss:0.25873\n",
      "[56]\tvalidation_0-logloss:0.02154\tvalidation_1-logloss:0.25844\n",
      "[57]\tvalidation_0-logloss:0.02141\tvalidation_1-logloss:0.25723\n",
      "[58]\tvalidation_0-logloss:0.02123\tvalidation_1-logloss:0.25924\n",
      "[59]\tvalidation_0-logloss:0.02110\tvalidation_1-logloss:0.26106\n",
      "[60]\tvalidation_0-logloss:0.02096\tvalidation_1-logloss:0.26231\n",
      "[61]\tvalidation_0-logloss:0.02083\tvalidation_1-logloss:0.26113\n",
      "[62]\tvalidation_0-logloss:0.02070\tvalidation_1-logloss:0.26108\n",
      "[63]\tvalidation_0-logloss:0.02058\tvalidation_1-logloss:0.26102\n",
      "[64]\tvalidation_0-logloss:0.02045\tvalidation_1-logloss:0.26285\n",
      "[65]\tvalidation_0-logloss:0.02033\tvalidation_1-logloss:0.26256\n",
      "[66]\tvalidation_0-logloss:0.02022\tvalidation_1-logloss:0.25985\n",
      "[67]\tvalidation_0-logloss:0.02010\tvalidation_1-logloss:0.26161\n",
      "[68]\tvalidation_0-logloss:0.01998\tvalidation_1-logloss:0.26049\n",
      "[69]\tvalidation_0-logloss:0.01987\tvalidation_1-logloss:0.26093\n",
      "[70]\tvalidation_0-logloss:0.01977\tvalidation_1-logloss:0.25877\n",
      "[71]\tvalidation_0-logloss:0.01966\tvalidation_1-logloss:0.26048\n",
      "[72]\tvalidation_0-logloss:0.01956\tvalidation_1-logloss:0.26022\n",
      "[73]\tvalidation_0-logloss:0.01945\tvalidation_1-logloss:0.25763\n",
      "[74]\tvalidation_0-logloss:0.01935\tvalidation_1-logloss:0.25927\n",
      "[75]\tvalidation_0-logloss:0.01926\tvalidation_1-logloss:0.25970\n",
      "[76]\tvalidation_0-logloss:0.01915\tvalidation_1-logloss:0.25861\n",
      "[77]\tvalidation_0-logloss:0.01906\tvalidation_1-logloss:0.25966\n",
      "오차 행렬\n",
      "[[35  2]\n",
      " [ 4 73]]\n",
      "정확도: 0.9474, 정밀도: 0.9733, 재현율: 0.9481,    F1: 0.9605, AUC:0.9933\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators=400,\n",
    "                            learning_rate=round(best['learning_rate'], 5),\n",
    "                            max_depth=int(best['max_depth']),\n",
    "                            min_child_weight=int(best['min_child_weight']),\n",
    "                            colsample_bytree=round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40fc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
