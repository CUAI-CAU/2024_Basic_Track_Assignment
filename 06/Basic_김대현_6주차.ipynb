{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 6 +4 * X+ np.random.randn(100,1)\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_updates(w1, w0, X, y, learning_rate=0.01):\n",
    "    N = len(y)\n",
    "    w1_update = np.zeros_like(w1)\n",
    "    w0_update = np.zeros_like(w0)\n",
    "    y_pred = np.dot(X, w1.T) + w0\n",
    "    diff = y-y_pred\n",
    "         \n",
    "    w0_factors = np.ones((N,1))\n",
    "\n",
    "    w1_update = -(2/N)*learning_rate*(np.dot(X.T, diff))\n",
    "    w0_update = -(2/N)*learning_rate*(np.dot(w0_factors.T, diff))    \n",
    "    \n",
    "    return w1_update, w0_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.zeros((1,1))\n",
    "w1 = np.zeros((1,1))\n",
    "y_pred = np.dot(X, w1.T) + w0\n",
    "diff = y-y_pred\n",
    "print(diff.shape)\n",
    "w0_factors = np.ones((100,1))\n",
    "w1_update = -(2/100)*0.01*(np.dot(X.T, diff))\n",
    "w0_update = -(2/100)*0.01*(np.dot(w0_factors.T, diff))   \n",
    "print(w1_update.shape, w0_update.shape)\n",
    "w1, w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_steps(X, y, iters=10000):\n",
    "    w0 = np.zeros((1,1))\n",
    "    w1 = np.zeros((1,1))\n",
    "    \n",
    "    for ind in range(iters):\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, X, y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "              \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(y, y_pred):\n",
    "    N = len(y) \n",
    "    cost = np.sum(np.square(y - y_pred))/N\n",
    "    return cost\n",
    "\n",
    "w1, w0 = gradient_descent_steps(X, y, iters=1000)\n",
    "print(\"w1:{0:.3f} w0:{1:.3f}\".format(w1[0,0], w0[0,0]))\n",
    "y_pred = w1[0,0] * X + w0\n",
    "print('Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_steps(X, y, batch_size=10, iters=1000):\n",
    "    w0 = np.zeros((1,1))\n",
    "    w1 = np.zeros((1,1))\n",
    "    prev_cost = 100000\n",
    "    iter_index =0\n",
    "    \n",
    "    for ind in range(iters):\n",
    "        np.random.seed(ind)\n",
    "        stochastic_random_index = np.random.permutation(X.shape[0])\n",
    "        sample_X = X[stochastic_random_index[0:batch_size]]\n",
    "        sample_y = y[stochastic_random_index[0:batch_size]]\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, sample_X, sample_y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "    \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w0 = stochastic_gradient_descent_steps(X, y, iters=1000)\n",
    "print(\"w1:\",round(w1[0,0],3),\"w0:\",round(w0[0,0],3))\n",
    "y_pred = w1[0,0] * X + w0\n",
    "print('Stochastic Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "bostonDF = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "\n",
    "bostonDF['PRICE'] = boston.target\n",
    "print('Boston 데이타셋 크기 :',bostonDF.shape)\n",
    "bostonDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16,8) , ncols=4 , nrows=2)\n",
    "lm_features = ['RM','ZN','INDUS','NOX','AGE','PTRATIO','LSTAT','RAD']\n",
    "for i , feature in enumerate(lm_features):\n",
    "    row = int(i/4)\n",
    "    col = i%4\n",
    "    sns.regplot(x=feature , y='PRICE',data=bostonDF , ax=axs[row][col])\n",
    "\n",
    "fig1 = plt.gcf()\n",
    "fig1.savefig('p322_boston.tif', format='tif', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_target ,test_size=0.3, random_state=156)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train ,y_train )\n",
    "y_preds = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))\n",
    "print('Variance score : {0:.3f}'.format(r2_score(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('절편 값:',lr.intercept_)\n",
    "print('회귀 계수값:', np.round(lr.coef_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.Series(data=np.round(lr.coef_, 1), index=X_data.columns )\n",
    "coeff.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "lr = LinearRegression()\n",
    "\n",
    "neg_mse_scores = cross_val_score(lr, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "X = np.arange(4).reshape(2,2)\n",
    "print('일차 단항식 계수 feature:\\n',X )\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X)\n",
    "poly_ftr = poly.transform(X)\n",
    "print('변환된 2차 다항식 계수 feature:\\n', poly_ftr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_func(X):\n",
    "    y = 1 + 2*X[:,0] + 3*X[:,0]**2 + 4*X[:,1]**3\n",
    "    print(X[:, 0])\n",
    "    print(X[:, 1])\n",
    "    return y\n",
    "\n",
    "X = np.arange(0,4).reshape(2,2)\n",
    "\n",
    "print('일차 단항식 계수 feature: \\n' ,X)\n",
    "y = polynomial_func(X)\n",
    "print('삼차 다항식 결정값: \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ftr = PolynomialFeatures(degree=3).fit_transform(X)\n",
    "print('3차 다항식 계수 feature: \\n',poly_ftr)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(poly_ftr,y)\n",
    "print('Polynomial 회귀 계수\\n' , np.round(model.coef_, 2))\n",
    "print('Polynomial 회귀 Shape :', model.coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def polynomial_func(X):\n",
    "    y = 1 + 2*X[:,0] + 3*X[:,0]**2 + 4*X[:,1]**3 \n",
    "    return y\n",
    "\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "                  ('linear', LinearRegression())])\n",
    "X = np.arange(4).reshape(2,2)\n",
    "y = polynomial_func(X)\n",
    "\n",
    "model = model.fit(X, y)\n",
    "print('Polynomial 회귀 계수\\n', np.round(model.named_steps['linear'].coef_, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "np.random.seed(0)\n",
    "n_samples = 30\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X.reshape(-1, 1), y)\n",
    "    \n",
    "    scores = cross_val_score(pipeline, X.reshape(-1, 1), y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    coefficients = pipeline.named_steps['linear_regression'].coef_\n",
    "    print('\\nDegree {0} 회귀 계수는 {1} 입니다.'.format(degrees[i], np.round(coefficients, 2)))\n",
    "    print('Degree {0} MSE 는 {1} 입니다.'.format(degrees[i], -1*np.mean(scores)))\n",
    "          \n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), '--', label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\"); plt.ylabel(\"y\"); plt.xlim((0, 1)); plt.ylim((-2, 2)); plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "bostonDF = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "\n",
    "bostonDF['PRICE'] = boston.target\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "\n",
    "\n",
    "ridge = Ridge(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 3))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0, 0.1, 1, 10, 100]\n",
    "\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha, avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axs = plt.subplots(figsize=(18,6) , nrows=1 , ncols=5)\n",
    "coeff_df = pd.DataFrame()\n",
    "\n",
    "for pos , alpha in enumerate(alphas) :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_data , y_target)\n",
    "    coeff = pd.Series(data=ridge.coef_ , index=X_data.columns )\n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    coeff = coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3,6)\n",
    "    sns.barplot(x=coeff.values , y=coeff.index, ax=axs[pos])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "sort_column = 'alpha:'+str(ridge_alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, \n",
    "                        verbose=True, return_coeff=True):\n",
    "    coeff_df = pd.DataFrame()\n",
    "    if verbose : print('####### ', model_name , '#######')\n",
    "    for param in params:\n",
    "        if model_name =='Ridge': model = Ridge(alpha=param)\n",
    "        elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "        elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        neg_mse_scores = cross_val_score(model, X_data_n, \n",
    "                                             y_target_n, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE: {1:.3f} '.format(param, avg_rmse))\n",
    "        \n",
    "        model.fit(X_data_n , y_target_n)\n",
    "        if return_coeff:\n",
    "            coeff = pd.Series(data=model.coef_ , index=X_data_n.columns )\n",
    "            colname='alpha:'+str(param)\n",
    "            coeff_df[colname] = coeff\n",
    "    \n",
    "    return coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_lasso_df =get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n=X_data, y_target_n=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_column = 'alpha:'+str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_elastic_df =get_linear_reg_eval('ElasticNet', params=elastic_alphas,\n",
    "                                      X_data_n=X_data, y_target_n=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_column = 'alpha:'+str(elastic_alphas[0])\n",
    "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method == 'MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else:\n",
    "        scaled_data = input_data\n",
    "\n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree, \n",
    "                                         include_bias=False).fit_transform(scaled_data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 1, 10, 100]\n",
    "scale_methods=[(None, None), ('Standard', None), ('Standard', 2), \n",
    "               ('MinMax', None), ('MinMax', 2), ('Log', None)]\n",
    "for scale_method in scale_methods:\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], \n",
    "                                    input_data=X_data)\n",
    "    print(X_data_scaled.shape, X_data.shape)\n",
    "    print('\\n## 변환 유형:{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n",
    "    get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled, \n",
    "                        y_target_n=y_target, verbose=False, return_coeff=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train , X_test, y_train , y_test = train_test_split(data_scaled, cancer.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "lr_clf = LogisticRegression() \n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "lr_preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('accuracy: {0:.3f}, roc_auc:{1:.3f}'.format(accuracy_score(y_test, lr_preds),\n",
    "                                                 roc_auc_score(y_test , lr_preds_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
    "for solver in solvers:\n",
    "    lr_clf = LogisticRegression(solver=solver, max_iter=600)\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    lr_preds = lr_clf.predict(X_test)\n",
    "    lr_preds_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print('solver:{0}, accuracy: {1:.3f}, roc_auc:{2:.3f}'.format(solver, \n",
    "                                                                  accuracy_score(y_test, lr_preds),\n",
    "                                                                  roc_auc_score(y_test , lr_preds_proba)))                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'solver':['liblinear', 'lbfgs'],\n",
    "        'penalty':['l2', 'l1'],\n",
    "        'C':[0.01, 0.1, 1, 5, 10]}\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3 )\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_, \n",
    "                                                  grid_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "bostonDF['PRICE'] = boston.target\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'], axis=1,inplace=False)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "neg_mse_scores = cross_val_score(rf, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(' 5 교차 검증의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n",
    "print(' 5 교차 검증의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n",
    "print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cv_prediction(model, X_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print('##### ',model.__class__.__name__ , ' #####')\n",
    "    print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, n_estimators=1000)\n",
    "xgb_reg = XGBRegressor(n_estimators=1000)\n",
    "lgb_reg = LGBMRegressor(n_estimators=1000)\n",
    "\n",
    "models = [dt_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
    "for model in models:  \n",
    "    get_model_cv_prediction(model, X_data, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "rf_reg.fit(X_data, y_target)\n",
    "\n",
    "feature_series = pd.Series(data=rf_reg.feature_importances_, index=X_data.columns )\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x= feature_series, y=feature_series.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "bostonDF_sample = bostonDF[['RM','PRICE']]\n",
    "bostonDF_sample = bostonDF_sample.sample(n=100,random_state=0)\n",
    "print(bostonDF_sample.shape)\n",
    "plt.figure()\n",
    "plt.scatter(bostonDF_sample.RM , bostonDF_sample.PRICE,c=\"darkorange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "rf_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "rf_reg7 = DecisionTreeRegressor(max_depth=7)\n",
    "\n",
    "X_test = np.arange(4.5, 8.5, 0.04).reshape(-1, 1)\n",
    "\n",
    "X_feature = bostonDF_sample['RM'].values.reshape(-1,1)\n",
    "y_target = bostonDF_sample['PRICE'].values.reshape(-1,1)\n",
    "\n",
    "lr_reg.fit(X_feature, y_target)\n",
    "rf_reg2.fit(X_feature, y_target)\n",
    "rf_reg7.fit(X_feature, y_target)\n",
    "\n",
    "pred_lr = lr_reg.predict(X_test)\n",
    "pred_rf2 = rf_reg2.predict(X_test)\n",
    "pred_rf7 = rf_reg7.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , (ax1, ax2, ax3) = plt.subplots(figsize=(14,4), ncols=3)\n",
    "\n",
    "ax1.set_title('Linear Regression')\n",
    "ax1.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")\n",
    "ax1.plot(X_test, pred_lr,label=\"linear\", linewidth=2 )\n",
    "\n",
    "ax2.set_title('Decision Tree Regression: \\n max_depth=2')\n",
    "ax2.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")\n",
    "ax2.plot(X_test, pred_rf2, label=\"max_depth:3\", linewidth=2 )\n",
    "\n",
    "ax3.set_title('Decision Tree Regression: \\n max_depth=7')\n",
    "ax3.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")\n",
    "ax3.plot(X_test, pred_rf7, label=\"max_depth:7\", linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bike Sharing Demand\n",
    "데이터 클랜징 및 가공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "bike_df = pd.read_csv('./bike_train.csv')\n",
    "print(bike_df.shape)\n",
    "bike_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_df['datetime'] = bike_df.datetime.apply(pd.to_datetime)\n",
    "\n",
    "bike_df['year'] = bike_df.datetime.apply(lambda x : x.year)\n",
    "bike_df['month'] = bike_df.datetime.apply(lambda x : x.month)\n",
    "bike_df['day'] = bike_df.datetime.apply(lambda x : x.day)\n",
    "bike_df['hour'] = bike_df.datetime.apply(lambda x: x.hour)\n",
    "bike_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['datetime','casual','registered']\n",
    "bike_df.drop(drop_columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16, 8), ncols=4, nrows=2)\n",
    "cat_features = ['year', 'month','season','weather','day', 'hour', 'holiday','workingday']\n",
    "for i, feature in enumerate(cat_features):\n",
    "    row = int(i/4)\n",
    "    col = i%4\n",
    "    sns.barplot(x=feature, y='count', data=bike_df, ax=axs[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def rmsle(y, pred):\n",
    "    log_y = np.log1p(y)\n",
    "    log_pred = np.log1p(pred)\n",
    "    squared_error = (log_y - log_pred) ** 2\n",
    "    rmsle = np.sqrt(np.mean(squared_error))\n",
    "    return rmsle\n",
    "\n",
    "def rmse(y,pred):\n",
    "    return np.sqrt(mean_squared_error(y,pred))\n",
    "\n",
    "def evaluate_regr(y,pred):\n",
    "    rmsle_val = rmsle(y,pred)\n",
    "    rmse_val = rmse(y,pred)\n",
    "    mae_val = mean_absolute_error(y,pred)\n",
    "    print('RMSLE: {0:.3f}, RMSE: {1:.3F}, MAE: {2:.3F}'.format(rmsle_val, rmse_val, mae_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression , Ridge , Lasso\n",
    "\n",
    "y_target = bike_df['count']\n",
    "X_features = bike_df.drop(['count'],axis=1,inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=0)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "pred = lr_reg.predict(X_test)\n",
    "\n",
    "evaluate_regr(y_test ,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_error_data(y_test, pred, n_tops = 5):\n",
    "    result_df = pd.DataFrame(y_test.values, columns=['real_count'])\n",
    "    result_df['predicted_count']= np.round(pred)\n",
    "    result_df['diff'] = np.abs(result_df['real_count'] - result_df['predicted_count'])\n",
    "    print(result_df.sort_values('diff', ascending=False)[:n_tops])\n",
    "    \n",
    "get_top_error_data(y_test,pred,n_tops=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_transform = np.log1p(y_target)\n",
    "y_log_transform.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target_log = np.log1p(y_target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target_log, test_size=0.3, random_state=0)\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "pred = lr_reg.predict(X_test)\n",
    "\n",
    "y_test_exp = np.expm1(y_test)\n",
    "\n",
    "pred_exp = np.expm1(pred)\n",
    "\n",
    "evaluate_regr(y_test_exp ,pred_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(lr_reg.coef_, index=X_features.columns)\n",
    "coef_sort = coef.sort_values(ascending=False)\n",
    "sns.barplot(x=coef_sort.values, y=coef_sort.index)\n",
    "plt.savefig('log_transform.tif', format='tif', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_ohe = pd.get_dummies(X_features, columns=['year', 'month','day', 'hour', 'holiday',\n",
    "                                              'workingday','season','weather'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features_ohe, y_target_log,\n",
    "                                                    test_size=0.3, random_state=0)\n",
    "\n",
    "def get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=False):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    if is_expm1 :\n",
    "        y_test = np.expm1(y_test)\n",
    "        pred = np.expm1(pred)\n",
    "    print('###',model.__class__.__name__,'###')\n",
    "    evaluate_regr(y_test, pred)\n",
    "lr_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=10)\n",
    "lasso_reg = Lasso(alpha=0.01)\n",
    "\n",
    "for model in [lr_reg, ridge_reg, lasso_reg]:\n",
    "    get_model_predict(model,X_train, X_test, y_train, y_test,is_expm1=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(lr_reg.coef_ , index=X_features_ohe.columns)\n",
    "coef_sort = coef.sort_values(ascending=False)[:20]\n",
    "sns.barplot(x=coef_sort.values , y=coef_sort.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=500)\n",
    "gbm_reg = GradientBoostingRegressor(n_estimators=500)\n",
    "xgb_reg = XGBRegressor(n_estimators=500)\n",
    "lgbm_reg = LGBMRegressor(n_estimators=500)\n",
    "\n",
    "for model in [rf_reg, gbm_reg, xgb_reg, lgbm_reg]:\n",
    "    get_model_predict(model,X_train.values, X_test.values, y_train.values, y_test.values,is_expm1=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "house_df_org = pd.read_csv('house_price.csv')\n",
    "house_df = house_df_org.copy()\n",
    "house_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 세트의 Shape:', house_df.shape)\n",
    "print('\\n전체 feature 들의 type \\n',house_df.dtypes.value_counts())\n",
    "isnull_series = house_df.isnull().sum()\n",
    "print('\\nNull 컬럼과 그 건수:\\n ', isnull_series[isnull_series > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Original Sale Price Histogram')\n",
    "plt.xticks(rotation=15)\n",
    "sns.histplot(house_df['SalePrice'], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Log Transformed Sale Price Histogram')\n",
    "log_SalePrice = np.log1p(house_df['SalePrice'])\n",
    "sns.histplot(log_SalePrice, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_SalePrice = house_df['SalePrice']\n",
    "house_df['SalePrice'] = np.log1p(house_df['SalePrice'])\n",
    "\n",
    "house_df.drop(['Id','PoolQC' , 'MiscFeature', 'Alley', 'Fence','FireplaceQu'], axis=1 , inplace=True)\n",
    "house_df.fillna(house_df.mean(),inplace=True)\n",
    "\n",
    "null_column_count = house_df.isnull().sum()[house_df.isnull().sum() > 0]\n",
    "print('## Null 피처의 Type :\\n', house_df.dtypes[null_column_count.index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('get_dummies() 수행 전 데이터 Shape:', house_df.shape)\n",
    "house_df_ohe = pd.get_dummies(house_df)\n",
    "print('get_dummies() 수행 후 데이터 Shape:', house_df_ohe.shape)\n",
    "\n",
    "null_column_count = house_df_ohe.isnull().sum()[house_df_ohe.isnull().sum() > 0]\n",
    "print('## Null 피처의 Type :\\n', house_df_ohe.dtypes[null_column_count.index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test , pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('{0} 로그 변환된 RMSE: {1}'.format(model.__class__.__name__,np.round(rmse, 3)))\n",
    "    return rmse\n",
    "\n",
    "def get_rmses(models):\n",
    "    rmses = [ ]\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        rmses.append(rmse)\n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_target = house_df_ohe['SalePrice']\n",
    "X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bottom_coef(model):\n",
    "    coef = pd.Series(model.coef_, index=X_features.columns)\n",
    "    \n",
    "    coef_high = coef.sort_values(ascending=False).head(10)\n",
    "    coef_low = coef.sort_values(ascending=False).tail(10)\n",
    "    return coef_high, coef_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefficient(models):\n",
    "    fig, axs = plt.subplots(figsize=(24,10),nrows=1, ncols=3)\n",
    "    fig.tight_layout() \n",
    "    for i_num, model in enumerate(models):\n",
    "        coef_high, coef_low = get_top_bottom_coef(model)\n",
    "        coef_concat = pd.concat( [coef_high , coef_low] )\n",
    "        axs[i_num].set_title(model.__class__.__name__+' Coeffiecents', size=25)\n",
    "        axs[i_num].tick_params(axis=\"y\",direction=\"in\", pad=-120)\n",
    "        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n",
    "            label.set_fontsize(22)\n",
    "        sns.barplot(x=coef_concat.values, y=coef_concat.index , ax=axs[i_num])\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def get_avg_rmse_cv(models):\n",
    "    for model in models:\n",
    "        rmse_list = np.sqrt(-cross_val_score(model, X_features, y_target,\n",
    "                                             scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "        rmse_avg = np.mean(rmse_list)\n",
    "        print('\\n{0} CV RMSE 값 리스트: {1}'.format( model.__class__.__name__, np.round(rmse_list, 3)))\n",
    "        print('{0} CV 평균 RMSE 값: {1}'.format( model.__class__.__name__, np.round(rmse_avg, 3)))\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_avg_rmse_cv(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def print_best_params(model, params):\n",
    "    grid_model = GridSearchCV(model, param_grid=params, \n",
    "                              scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_model.fit(X_features, y_target)\n",
    "    rmse = np.sqrt(-1* grid_model.best_score_)\n",
    "    print('{0} 5 CV 시 최적 평균 RMSE 값: {1}, 최적 alpha:{2}'.format(model.__class__.__name__,\n",
    "                                        np.round(rmse, 4), grid_model.best_params_))\n",
    "    return grid_model.best_estimator_\n",
    "\n",
    "ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\n",
    "lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\n",
    "best_rige = print_best_params(ridge_reg, ridge_params)\n",
    "best_lasso = print_best_params(lasso_reg, lasso_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "ridge_reg = Ridge(alpha=12)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "features_index = house_df.dtypes[house_df.dtypes != 'object'].index\n",
    "skew_features = house_df[features_index].apply(lambda x : skew(x))\n",
    "skew_features_top = skew_features[skew_features > 1]\n",
    "print(skew_features_top.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df[skew_features_top.index] = np.log1p(house_df[skew_features_top.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df_ohe = pd.get_dummies(house_df)\n",
    "y_target = house_df_ohe['SalePrice']\n",
    "X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)\n",
    "\n",
    "ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\n",
    "lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\n",
    "best_ridge = print_best_params(ridge_reg, ridge_params)\n",
    "best_lasso = print_best_params(lasso_reg, lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "ridge_reg = Ridge(alpha=10)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = house_df_org['GrLivArea'], y = house_df_org['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=15)\n",
    "plt.xlabel('GrLivArea', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = house_df_ohe['GrLivArea'] > np.log1p(4000)\n",
    "cond2 = house_df_ohe['SalePrice'] < np.log1p(500000)\n",
    "outlier_index = house_df_ohe[cond1 & cond2].index\n",
    "\n",
    "print('아웃라이어 레코드 index :', outlier_index.values)\n",
    "print('아웃라이어 삭제 전 house_df_ohe shape:', house_df_ohe.shape)\n",
    "house_df_ohe.drop(outlier_index , axis=0, inplace=True)\n",
    "print('아웃라이어 삭제 후 house_df_ohe shape:', house_df_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = house_df_ohe['SalePrice']\n",
    "X_features = house_df_ohe.drop('SalePrice',axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=156)\n",
    "\n",
    "ridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\n",
    "lasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\n",
    "best_ridge = print_best_params(ridge_reg, ridge_params)\n",
    "best_lasso = print_best_params(lasso_reg, lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "ridge_reg = Ridge(alpha=8)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {'n_estimators':[1000]}\n",
    "xgb_reg = XGBRegressor(n_estimators=1000, learning_rate=0.05, \n",
    "                       colsample_bytree=0.5, subsample=0.8)\n",
    "best_xgb = print_best_params(xgb_reg, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_params = {'n_estimators':[1000]}\n",
    "lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "best_lgbm = print_best_params(lgbm_reg, lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(model):\n",
    "    ftr_importances_values = model.feature_importances_\n",
    "    ftr_importances = pd.Series(ftr_importances_values, index=X_features.columns  )\n",
    "    ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "    return ftr_top20\n",
    "\n",
    "def visualize_ftr_importances(models):\n",
    "    fig, axs = plt.subplots(figsize=(24,10),nrows=1, ncols=2)\n",
    "    fig.tight_layout() \n",
    "    for i_num, model in enumerate(models):\n",
    "        ftr_top20 = get_top_features(model)\n",
    "        axs[i_num].set_title(model.__class__.__name__+' Feature Importances', size=25)\n",
    "        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n",
    "            label.set_fontsize(22)\n",
    "        sns.barplot(x=ftr_top20.values, y=ftr_top20.index , ax=axs[i_num])\n",
    "\n",
    "models = [best_xgb, best_lgbm]\n",
    "visualize_ftr_importances(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_pred(preds):\n",
    "    for key in preds.keys():\n",
    "        pred_value = preds[key]\n",
    "        mse = mean_squared_error(y_test , pred_value)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print('{0} 모델의 RMSE: {1}'.format(key, rmse))\n",
    "\n",
    "ridge_reg = Ridge(alpha=8)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "ridge_pred = ridge_reg.predict(X_test)\n",
    "lasso_pred = lasso_reg.predict(X_test)\n",
    "\n",
    "pred = 0.4 * ridge_pred + 0.6 * lasso_pred\n",
    "preds = {'최종 혼합': pred,\n",
    "         'Ridge': ridge_pred,\n",
    "         'Lasso': lasso_pred}\n",
    "get_rmse_pred(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(n_estimators=1000, learning_rate=0.05, \n",
    "                       colsample_bytree=0.5, subsample=0.8)\n",
    "lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "lgbm_reg.fit(X_train, y_train)\n",
    "xgb_pred = xgb_reg.predict(X_test)\n",
    "lgbm_pred = lgbm_reg.predict(X_test)\n",
    "\n",
    "pred = 0.5 * xgb_pred + 0.5 * lgbm_pred\n",
    "preds = {'최종 혼합': pred,\n",
    "         'XGBM': xgb_pred,\n",
    "         'LGBM': lgbm_pred}\n",
    "        \n",
    "get_rmse_pred(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        model.fit(X_tr , y_tr)       \n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = X_train.values\n",
    "X_test_n = X_test.values\n",
    "y_train_n = y_train.values\n",
    "\n",
    "ridge_train, ridge_test = get_stacking_base_datasets(ridge_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "lasso_train, lasso_test = get_stacking_base_datasets(lasso_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "xgb_train, xgb_test = get_stacking_base_datasets(xgb_reg, X_train_n, y_train_n, X_test_n, 5)  \n",
    "lgbm_train, lgbm_test = get_stacking_base_datasets(lgbm_reg, X_train_n, y_train_n, X_test_n, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stack_final_X_train = np.concatenate((ridge_train, lasso_train, \n",
    "                                      xgb_train, lgbm_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((ridge_test, lasso_test, \n",
    "                                     xgb_test, lgbm_test), axis=1)\n",
    "\n",
    "meta_model_lasso = Lasso(alpha=0.0005)\n",
    "\n",
    "meta_model_lasso.fit(Stack_final_X_train, y_train)\n",
    "final = meta_model_lasso.predict(Stack_final_X_test)\n",
    "mse = mean_squared_error(y_test , final)\n",
    "rmse = np.sqrt(mse)\n",
    "print('스태킹 회귀 모델의 최종 RMSE 값은:', rmse)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
