{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means를 이용한 붓꽃(Iris) 데이터 셋 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "iris = load_iris()\n",
    "# 보다 편리한 데이터 Handling을 위해 DataFrame으로 변환\n",
    "irisDF = pd.DataFrame(data=iris.data, columns=['sepal_length','sepal_width','petal_length','petal_width'])\n",
    "irisDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개정판 소스 코드 수정(2019.12.24)\n",
    "# 가장 중요한 parameter : n_clusters(군집 중심점의 개수)\n",
    "# init은 보통 임의로 설정하지 않고 k-means++로 설정한다\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300,random_state=0)\n",
    "kmeans.fit(irisDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 0 2 2 2 2\n",
      " 2 2 0 0 2 2 2 2 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 2 2 0 2\n",
      " 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  cluster\n",
      "0       1          50\n",
      "1       0          48\n",
      "        2           2\n",
      "2       0          14\n",
      "        2          36\n",
      "Name: sepal_length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# irisDF['cluster']=kmeans.labels_ 개정 소스코드 변경(2019.12.24)\n",
    "\n",
    "irisDF['target'] = iris.target\n",
    "irisDF['cluster']=kmeans.labels_\n",
    "iris_result = irisDF.groupby(['target','cluster'])['sepal_length'].count()\n",
    "print(iris_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 2차원 평면에 적합하도록 pca 진행\n",
    "pca = PCA(n_components=2)\n",
    "pca_transformed = pca.fit_transform(iris.data)\n",
    "\n",
    "irisDF['pca_x'] = pca_transformed[:,0]\n",
    "irisDF['pca_y'] = pca_transformed[:,1]\n",
    "irisDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster 값이 0, 1, 2 인 경우마다 별도의 Index로 추출\n",
    "marker0_ind = irisDF[irisDF['cluster']==0].index\n",
    "marker1_ind = irisDF[irisDF['cluster']==1].index\n",
    "marker2_ind = irisDF[irisDF['cluster']==2].index\n",
    "\n",
    "# cluster값 0, 1, 2에 해당하는 Index로 각 cluster 레벨의 pca_x, pca_y 값 추출. o, s, ^ 로 marker 표시\n",
    "plt.scatter(x=irisDF.loc[marker0_ind,'pca_x'], y=irisDF.loc[marker0_ind,'pca_y'], marker='o') \n",
    "plt.scatter(x=irisDF.loc[marker1_ind,'pca_x'], y=irisDF.loc[marker1_ind,'pca_y'], marker='s')\n",
    "plt.scatter(x=irisDF.loc[marker2_ind,'pca_x'], y=irisDF.loc[marker2_ind,'pca_y'], marker='^')\n",
    "\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('3 Clusters Visualization by 2 PCA Components')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering 알고리즘 테스트를 위한 데이터 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "%matplotlib inline\n",
    "\n",
    "X, y = make_blobs(n_samples=200, n_features=2, centers=3, cluster_std=0.8, random_state=0)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# y target 값의 분포를 확인\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clusterDF = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])\n",
    "clusterDF['target'] = y\n",
    "clusterDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = np.unique(y)\n",
    "# 각 target별 scatter plot 의 marker 값들. \n",
    "markers=['o', 's', '^', 'P','D','H','x']\n",
    "# 3개의 cluster 영역으로 구분한 데이터 셋을 생성했으므로 target_list는 [0,1,2]\n",
    "# target==0, target==1, target==2 로 scatter plot을 marker별로 생성. \n",
    "for target in target_list:\n",
    "    target_cluster = clusterDF[clusterDF['target']==target]\n",
    "    plt.scatter(x=target_cluster['ftr1'], y=target_cluster['ftr2'], edgecolor='k', marker=markers[target] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans 객체를 이용하여 X 데이터를 K-Means 클러스터링 수행 \n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=200, random_state=0)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "clusterDF['kmeans_label']  = cluster_labels\n",
    "\n",
    "#cluster_centers_ 는 개별 클러스터의 중심 위치 좌표 시각화를 위해 추출\n",
    "centers = kmeans.cluster_centers_\n",
    "unique_labels = np.unique(cluster_labels)\n",
    "markers=['o', 's', '^', 'P','D','H','x']\n",
    "\n",
    "# 군집된 label 유형별로 iteration 하면서 marker 별로 scatter plot 수행. \n",
    "for label in unique_labels:\n",
    "    label_cluster = clusterDF[clusterDF['kmeans_label']==label]\n",
    "    center_x_y = centers[label]\n",
    "    plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], edgecolor='k', \n",
    "                marker=markers[label] )\n",
    "    \n",
    "    # 군집별 중심 위치 좌표 시각화 \n",
    "    plt.scatter(x=center_x_y[0], y=center_x_y[1], s=200, color='white',\n",
    "                alpha=0.9, edgecolor='k', marker=markers[label])\n",
    "    plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k', edgecolor='k', \n",
    "                marker='$%d$' % label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusterDF.groupby('target')['kmeans_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "# 실루엣 분석 metric 값을 구하기 위한 API 추가\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "iris = load_iris()\n",
    "feature_names = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "irisDF = pd.DataFrame(data=iris.data, columns=feature_names)\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300,random_state=0).fit(irisDF)\n",
    "\n",
    "irisDF['cluster'] = kmeans.labels_\n",
    "\n",
    "# iris 의 모든 개별 데이터에 실루엣 계수값을 구함. \n",
    "score_samples = silhouette_samples(iris.data, irisDF['cluster'])\n",
    "print('silhouette_samples( ) return 값의 shape' , score_samples.shape)\n",
    "\n",
    "# irisDF에 실루엣 계수 컬럼 추가\n",
    "irisDF['silhouette_coeff'] = score_samples\n",
    "\n",
    "# 모든 데이터의 평균 실루엣 계수값을 구함. \n",
    "average_score = silhouette_score(iris.data, irisDF['cluster'])\n",
    "print('붓꽃 데이터셋 Silhouette Analysis Score:{0:.3f}'.format(average_score))\n",
    "\n",
    "irisDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDF.groupby('cluster')['silhouette_coeff'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터별 평균 실루엣 계수의 시각화를 통한 클러스터 개수 최적화 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성\n",
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_blobs 을 통해 clustering 을 위한 4개의 클러스터 중심의 500개 2차원 데이터 셋 생성  \n",
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=500, n_features=2, centers=4, cluster_std=1, \\\n",
    "                  center_box=(-10.0, 10.0), shuffle=True, random_state=1)  \n",
    "\n",
    "# cluster 개수를 2개, 3개, 4개, 5개 일때의 클러스터별 실루엣 계수 평균값을 시각화 \n",
    "# 4개일 때 가장 적합\n",
    "visualize_silhouette([ 2, 3, 4, 5], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris=load_iris()\n",
    "visualize_silhouette([ 2, 3, 4,5 ], iris.data)\n",
    "# 2개일 때 가장 적합\n",
    "# 3개일 때는 2, 0에서 개별 실루엣 계수가 너무 작음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Shift 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "X, y = make_blobs(n_samples=200, n_features=2, centers=3, \n",
    "                  cluster_std=0.7, random_state=0)\n",
    "\n",
    "meanshift= MeanShift(bandwidth=0.8)\n",
    "cluster_labels = meanshift.fit_predict(X)\n",
    "print('cluster labels 유형:', np.unique(cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanshift= MeanShift(bandwidth=1)\n",
    "cluster_labels = meanshift.fit_predict(X)\n",
    "print('cluster labels 유형:', np.unique(cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import estimate_bandwidth\n",
    "\n",
    "bandwidth = estimate_bandwidth(X)\n",
    "print('bandwidth 값:', round(bandwidth,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "clusterDF = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])\n",
    "clusterDF['target'] = y\n",
    "\n",
    "# estimate_bandwidth()로 최적의 bandwidth 계산\n",
    "best_bandwidth = estimate_bandwidth(X)\n",
    "\n",
    "meanshift= MeanShift(bandwidth=best_bandwidth)\n",
    "cluster_labels = meanshift.fit_predict(X)\n",
    "print('cluster labels 유형:',np.unique(cluster_labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "clusterDF['meanshift_label']  = cluster_labels\n",
    "centers = meanshift.cluster_centers_\n",
    "unique_labels = np.unique(cluster_labels)\n",
    "markers=['o', 's', '^', 'x', '*']\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_cluster = clusterDF[clusterDF['meanshift_label']==label]\n",
    "    center_x_y = centers[label]\n",
    "    # 군집별로 다른 마커로 산점도 적용\n",
    "    plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], edgecolor='k', marker=markers[label] )\n",
    "    \n",
    "    # 군집별 중심 표현\n",
    "    plt.scatter(x=center_x_y[0], y=center_x_y[1], s=200, color='gray', alpha=0.9, marker=markers[label])\n",
    "    plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k', edgecolor='k', marker='$%d$' % label)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# 데이터 만들 때의 label과는 값이 다르게 나올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusterDF.groupby('target')['meanshift_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM 을 이용한 붓꽃 데이터 셋 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "iris = load_iris()\n",
    "feature_names = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# 보다 편리한 데이타 Handling을 위해 DataFrame으로 변환\n",
    "irisDF = pd.DataFrame(data=iris.data, columns=feature_names)\n",
    "irisDF['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# GMM에서 가장 중요한 parameter는 n_components이다.\n",
    "# gaussian mixture의 모델의 총 개수로 군집의 개수를 정하는 데 중요한 역할을 한다.\n",
    "gmm = GaussianMixture(n_components=3, random_state=0).fit(iris.data)\n",
    "gmm_cluster_labels = gmm.predict(iris.data)\n",
    "\n",
    "# 클러스터링 결과를 irisDF 의 'gmm_cluster' 컬럼명으로 저장\n",
    "irisDF['gmm_cluster'] = gmm_cluster_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "# target 값에 따라서 gmm_cluster 값이 어떻게 매핑되었는지 확인. \n",
    "iris_result = irisDF.groupby(['target'])['gmm_cluster'].value_counts()\n",
    "print(iris_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300,random_state=0).fit(iris.data)\n",
    "kmeans_cluster_labels = kmeans.predict(iris.data)\n",
    "irisDF['kmeans_cluster'] = kmeans_cluster_labels\n",
    "iris_result = irisDF.groupby(['target'])['kmeans_cluster'].value_counts()\n",
    "print(iris_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 클러스터 결과를 담은 DataFrame과 사이킷런의 Cluster 객체등을 인자로 받아 클러스터링 결과를 시각화하는 함수  \n",
    "def visualize_cluster_plot(clusterobj, dataframe, label_name, iscenter=True):\n",
    "    if iscenter :\n",
    "        centers = clusterobj.cluster_centers_\n",
    "        \n",
    "    unique_labels = np.unique(dataframe[label_name].values)\n",
    "    markers=['o', 's', '^', 'x', '*']\n",
    "    isNoise=False\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_cluster = dataframe[dataframe[label_name]==label]\n",
    "        if label == -1:\n",
    "            cluster_legend = 'Noise'\n",
    "            isNoise=True\n",
    "        else :\n",
    "            cluster_legend = 'Cluster '+str(label)\n",
    "        \n",
    "        plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], s=70,\\\n",
    "                    edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "        \n",
    "        if iscenter:\n",
    "            center_x_y = centers[label]\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=250, color='white',\n",
    "                        alpha=0.9, edgecolor='k', marker=markers[label])\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k',\\\n",
    "                        edgecolor='k', marker='$%d$' % label)\n",
    "    if isNoise:\n",
    "        legend_loc='upper center'\n",
    "    else: legend_loc='upper right'\n",
    "    \n",
    "    plt.legend(loc=legend_loc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# make_blobs() 로 300개의 데이터 셋, 3개의 cluster 셋, cluster_std=0.5 을 만듬. \n",
    "X, y = make_blobs(n_samples=300, n_features=2, centers=3, cluster_std=0.5, random_state=0)\n",
    "\n",
    "# 길게 늘어난 타원형의 데이터 셋을 생성하기 위해 변환함. \n",
    "transformation = [[0.60834549, -0.63667341], [-0.40887718, 0.85253229]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "# feature 데이터 셋과 make_blobs( ) 의 y 결과 값을 DataFrame으로 저장\n",
    "clusterDF = pd.DataFrame(data=X_aniso, columns=['ftr1', 'ftr2'])\n",
    "clusterDF['target'] = y\n",
    "# 생성된 데이터 셋을 target 별로 다른 marker 로 표시하여 시각화 함. \n",
    "visualize_cluster_plot(None, clusterDF, 'target', iscenter=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 Cluster 기반 Kmeans 를 X_aniso 데이터 셋에 적용 \n",
    "kmeans = KMeans(3, random_state=0)\n",
    "kmeans_label = kmeans.fit_predict(X_aniso)\n",
    "clusterDF['kmeans_label'] = kmeans_label\n",
    "\n",
    "visualize_cluster_plot(kmeans, clusterDF, 'kmeans_label',iscenter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 n_components기반 GMM을 X_aniso 데이터 셋에 적용 \n",
    "gmm = GaussianMixture(n_components=3, random_state=0)\n",
    "gmm_label = gmm.fit(X_aniso).predict(X_aniso)\n",
    "clusterDF['gmm_label'] = gmm_label\n",
    "\n",
    "# GaussianMixture는 cluster_centers_ 속성이 없으므로 iscenter를 False로 설정. \n",
    "visualize_cluster_plot(gmm, clusterDF, 'gmm_label',iscenter=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### KMeans Clustering ###')\n",
    "print(clusterDF.groupby('target')['kmeans_label'].value_counts())\n",
    "print('\\n### Gaussian Mixture Clustering ###')\n",
    "print(clusterDF.groupby('target')['gmm_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN 적용하기 – 붓꽃 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "iris = load_iris()\n",
    "feature_names = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "# 보다 편리한 데이타 Handling을 위해 DataFrame으로 변환\n",
    "irisDF = pd.DataFrame(data=iris.data, columns=feature_names)\n",
    "irisDF['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=8, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "irisDF['dbscan_cluster'] = dbscan_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "print(iris_result)\n",
    "# DBSCAN은 군집의 개수를 알고리즘에 따라 자동으로 지정\n",
    "# target 값의 유형이 3가지인데 군집이 2개라고 효율이 떨어지는 건 아니며 오히려 붓꽃에서는 2개가 효율적임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 클러스터 결과를 담은 DataFrame과 사이킷런의 Cluster 객체등을 인자로 받아 클러스터링 결과를 시각화하는 함수  \n",
    "def visualize_cluster_plot(clusterobj, dataframe, label_name, iscenter=True):\n",
    "    if iscenter :\n",
    "        centers = clusterobj.cluster_centers_\n",
    "        \n",
    "    unique_labels = np.unique(dataframe[label_name].values)\n",
    "    markers=['o', 's', '^', 'x', '*']\n",
    "    isNoise=False\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_cluster = dataframe[dataframe[label_name]==label]\n",
    "        if label == -1:\n",
    "            cluster_legend = 'Noise'\n",
    "            isNoise=True\n",
    "        else :\n",
    "            cluster_legend = 'Cluster '+str(label)\n",
    "        \n",
    "        plt.scatter(x=label_cluster['ftr1'], y=label_cluster['ftr2'], s=70,\\\n",
    "                    edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "        \n",
    "        if iscenter:\n",
    "            center_x_y = centers[label]\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=250, color='white',\n",
    "                        alpha=0.9, edgecolor='k', marker=markers[label])\n",
    "            plt.scatter(x=center_x_y[0], y=center_x_y[1], s=70, color='k',\\\n",
    "                        edgecolor='k', marker='$%d$' % label)\n",
    "    if isNoise:\n",
    "        legend_loc='upper center'\n",
    "    else: legend_loc='upper right'\n",
    "    \n",
    "    plt.legend(loc=legend_loc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# 2차원으로 시각화하기 위해 PCA n_componets=2로 피처 데이터 세트 변환\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "pca_transformed = pca.fit_transform(iris.data)\n",
    "# visualize_cluster_2d( ) 함수는 ftr1, ftr2 컬럼을 좌표에 표현하므로 PCA 변환값을 해당 컬럼으로 생성\n",
    "irisDF['ftr1'] = pca_transformed[:,0]\n",
    "irisDF['ftr2'] = pca_transformed[:,1]\n",
    "\n",
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=8, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "irisDF['dbscan_cluster'] = dbscan_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "print(iris_result)\n",
    "\n",
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.6, min_samples=16, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(iris.data)\n",
    "\n",
    "irisDF['dbscan_cluster'] = dbscan_labels\n",
    "irisDF['target'] = iris.target\n",
    "\n",
    "iris_result = irisDF.groupby(['target'])['dbscan_cluster'].value_counts()\n",
    "print(iris_result)\n",
    "visualize_cluster_plot(dbscan, irisDF, 'dbscan_cluster', iscenter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN 적용하기 – make_circles() 데이터 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X, y = make_circles(n_samples=1000, shuffle=True, noise=0.05, random_state=0, factor=0.5)\n",
    "clusterDF = pd.DataFrame(data=X, columns=['ftr1', 'ftr2'])\n",
    "clusterDF['target'] = y\n",
    "\n",
    "visualize_cluster_plot(None, clusterDF, 'target', iscenter=False)\n",
    "\n",
    "# k-means이나 gmm으로는 해결하기 어려운 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans로 make_circles( ) 데이터 셋을 클러스터링 수행. \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, max_iter=1000, random_state=0)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "clusterDF['kmeans_cluster'] = kmeans_labels\n",
    "\n",
    "visualize_cluster_plot(kmeans, clusterDF, 'kmeans_cluster', iscenter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM으로 make_circles( ) 데이터 셋을 클러스터링 수행. \n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, random_state=0)\n",
    "gmm_label = gmm.fit(X).predict(X)\n",
    "clusterDF['gmm_cluster'] = gmm_label\n",
    "\n",
    "visualize_cluster_plot(gmm, clusterDF, 'gmm_cluster', iscenter=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN으로 make_circles( ) 데이터 셋을 클러스터링 수행. \n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=10, metric='euclidean')\n",
    "dbscan_labels = dbscan.fit_predict(X)\n",
    "clusterDF['dbscan_cluster'] = dbscan_labels\n",
    "\n",
    "visualize_cluster_plot(dbscan, clusterDF, 'dbscan_cluster', iscenter=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 로딩과 데이터 클린징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "retail_df = pd.read_excel(io='Online Retail.xlsx')\n",
    "retail_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df[retail_df['Quantity'] > 0]\n",
    "retail_df = retail_df[retail_df['UnitPrice'] > 0]\n",
    "retail_df = retail_df[retail_df['CustomerID'].notnull()]\n",
    "print(retail_df.shape)\n",
    "retail_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df['Country'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df[retail_df['Country']=='United Kingdom']\n",
    "print(retail_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM 기반 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df['sale_amount'] = retail_df['Quantity'] * retail_df['UnitPrice']\n",
    "retail_df['CustomerID'] = retail_df['CustomerID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retail_df['CustomerID'].value_counts().head(5))\n",
    "print(retail_df.groupby('CustomerID')['sale_amount'].sum().sort_values(ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df.groupby(['InvoiceNo','StockCode'])['InvoiceNo'].count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame의 groupby() 의 multiple 연산을 위해 agg() 이용\n",
    "# Recency는 InvoiceDate 컬럼의 max() 에서 데이터 가공\n",
    "# Frequency는 InvoiceNo 컬럼의 count() , Monetary value는 sale_amount 컬럼의 sum()\n",
    "aggregations = {\n",
    "    'InvoiceDate': 'max',\n",
    "    'InvoiceNo': 'count',\n",
    "    'sale_amount':'sum'\n",
    "}\n",
    "cust_df = retail_df.groupby('CustomerID').agg(aggregations)\n",
    "# groupby된 결과 컬럼값을 Recency, Frequency, Monetary로 변경\n",
    "cust_df = cust_df.rename(columns = {'InvoiceDate':'Recency',\n",
    "                                    'InvoiceNo':'Frequency',\n",
    "                                    'sale_amount':'Monetary'\n",
    "                                   }\n",
    "                        )\n",
    "cust_df = cust_df.reset_index()\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "cust_df['Recency'] = dt.datetime(2011,12,10) - cust_df['Recency']\n",
    "cust_df['Recency'] = cust_df['Recency'].apply(lambda x: x.days+1)\n",
    "print('cust_df 로우와 컬럼 건수는 ',cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM 기반 고객 세그먼테이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(figsize=(12,4), nrows=1, ncols=3)\n",
    "ax1.set_title('Recency Histogram')\n",
    "ax1.hist(cust_df['Recency'])\n",
    "\n",
    "ax2.set_title('Frequency Histogram')\n",
    "ax2.hist(cust_df['Frequency'])\n",
    "\n",
    "ax3.set_title('Monetary Histogram')\n",
    "ax3.hist(cust_df['Monetary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df[['Recency','Frequency','Monetary']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "X_features = cust_df[['Recency','Frequency','Monetary']].values\n",
    "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features_scaled)\n",
    "cust_df['cluster_label'] = labels\n",
    "\n",
    "print('실루엣 스코어는 : {0:.3f}'.format(silhouette_score(X_features_scaled,labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 실루엣 계수를 면적으로 시각화한 함수 작성  \n",
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "    \n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "    \n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "        \n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "        \n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        \n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "            \n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "            \n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "            \n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 여러개의 클러스터링 갯수를 List로 입력 받아 각각의 클러스터링 결과를 시각화 \n",
    "def visualize_kmeans_plot_multi(cluster_lists, X_features):\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.decomposition import PCA\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 만큼의 sub figures를 가지는 axs 생성 \n",
    "    n_cols = len(cluster_lists)\n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "    \n",
    "    # 입력 데이터의 FEATURE가 여러개일 경우 2차원 데이터 시각화가 어려우므로 PCA 변환하여 2차원 시각화\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_transformed = pca.fit_transform(X_features)\n",
    "    dataframe = pd.DataFrame(pca_transformed, columns=['PCA1','PCA2'])\n",
    "    \n",
    "     # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 KMeans 클러스터링 수행하고 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "        \n",
    "        # KMeans 클러스터링으로 클러스터링 결과를 dataframe에 저장. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=0)\n",
    "        cluster_labels = clusterer.fit_predict(pca_transformed)\n",
    "        dataframe['cluster']=cluster_labels\n",
    "        \n",
    "        unique_labels = np.unique(clusterer.labels_)\n",
    "        markers=['o', 's', '^', 'x', '*']\n",
    "       \n",
    "        # 클러스터링 결과값 별로 scatter plot 으로 시각화\n",
    "        for label in unique_labels:\n",
    "            label_df = dataframe[dataframe['cluster']==label]\n",
    "            if label == -1:\n",
    "                cluster_legend = 'Noise'\n",
    "            else :\n",
    "                cluster_legend = 'Cluster '+str(label)           \n",
    "            axs[ind].scatter(x=label_df['PCA1'], y=label_df['PCA2'], s=70,\\\n",
    "                        edgecolor='k', marker=markers[label], label=cluster_legend)\n",
    "\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster))    \n",
    "        axs[ind].legend(loc='upper right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette([2,3,4,5],X_features_scaled)\n",
    "visualize_kmeans_plot_multi([2,3,4,5],X_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log 변환을 통해 데이터 변환\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "# Recency, Frequecny, Monetary 컬럼에 np.log1p() 로 Log Transformation\n",
    "cust_df['Recency_log'] = np.log1p(cust_df['Recency'])\n",
    "cust_df['Frequency_log'] = np.log1p(cust_df['Frequency'])\n",
    "cust_df['Monetary_log'] = np.log1p(cust_df['Monetary'])\n",
    "\n",
    "# Log Transformation 데이터에 StandardScaler 적용\n",
    "X_features = cust_df[['Recency_log','Frequency_log','Monetary_log']].values\n",
    "X_features_scaled = StandardScaler().fit_transform(X_features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels = kmeans.fit_predict(X_features_scaled)\n",
    "cust_df['cluster_label'] = labels\n",
    "\n",
    "print('실루엣 스코어는 : {0:.3f}'.format(silhouette_score(X_features_scaled,labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette([2,3,4,5],X_features_scaled)\n",
    "visualize_kmeans_plot_multi([2,3,4,5],X_features_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
